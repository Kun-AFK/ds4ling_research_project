# ─────────────────────────────────────────────────────────────────────────────
# 6. 普通最小二乘回归（OLS）
# ─────────────────────────────────────────────────────────────────────────────
model_ols <- lm(quality ~ ., data = data_wine_raw)
summary(model_ols)

# 回归诊断图（残差、QQ、杠杆点等）
par(mfrow = c(2, 2))
plot(model_ols)
par(mfrow = c(1, 1))


# ─────────────────────────────────────────────────────────────────────────────
# 7. Lasso 回归：glmnet 包
# ─────────────────────────────────────────────────────────────────────────────
# install.packages("glmnet")  # 如未安装，请先运行
library(glmnet)

# 准备矩阵：x（自变量），y（因变量）
x <- model.matrix(quality ~ ., data = data_wine_raw)[, -1]
y <- data_wine_raw$quality

# 7.1 10 折交叉验证找最佳 λ
set.seed(2025)
cv_lasso <- cv.glmnet(x, y, alpha = 1, family = "gaussian", standardize = TRUE, nfolds = 10)
plot(cv_lasso)                # 误差曲线
best_lambda <- cv_lasso$lambda.min
best_lambda

# 7.2 提取系数
lasso_coef <- coef(cv_lasso, s = "lambda.min")
print(lasso_coef)             # 非零系数即为 Lasso 选出的变量


# ─────────────────────────────────────────────────────────────────────────────
# 8. 模型性能对比（交叉验证下 RMSE）
# ─────────────────────────────────────────────────────────────────────────────
# install.packages("caret")
library(caret)

set.seed(2025)
train_ctrl <- trainControl(method = "cv", number = 10)

# OLS CV
ols_cv <- train(
  quality ~ .,
  data      = data_wine_raw,
  method    = "lm",
  trControl = train_ctrl
)

# Lasso CV
lasso_cv <- train(
  quality ~ .,
  data      = data_wine_raw,
  method    = "glmnet",
  trControl = train_ctrl,
  tuneGrid  = expand.grid(alpha = 1, lambda = cv_lasso$lambda)
)

# 输出模型性能
ols_cv
lasso_cv


# ─────────────────────────────────────────────────────────────────────────────
# 9. 贝叶斯回归：rstanarm 包
# ─────────────────────────────────────────────────────────────────────────────
# install.packages("rstanarm", repos = "https://cloud.r-project.org/")
library(rstanarm)

# 9.1 拟合模型（默认：Gaussian family）
model_bayes <- stan_glm(
  quality ~ .,
  data            = data_wine_raw,
  family          = gaussian(),
  prior           = normal(0, 1),        # 固定效应先验
  prior_intercept = normal(0, 5),        # 截距先验
  chains          = 4,
  cores           = parallel::detectCores(),
  iter            = 2000,
  seed            = 2025
)

print(model_bayes, digits = 2)

# 9.2 后验区间
posterior_interval(model_bayes, prob = 0.95)

# 9.3 后验预测检验（Posterior Predictive Check）
pp_check(model_bayes)        # KDE 对比


# （可选）10. 主成分分析（PCA）示例
pca_res <- prcomp(data_wine_raw %>% select(-quality), center = TRUE, scale. = TRUE)
summary(pca_res)
biplot(pca_res, xlabs = rep(".", nrow(data_wine_raw)))
